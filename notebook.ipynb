{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:26.653412Z",
     "start_time": "2025-06-18T16:09:26.080854Z"
    }
   },
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:28.318897Z",
     "start_time": "2025-06-18T16:09:26.671548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load datasets\n",
    "\n",
    "# customers\n",
    "customers = pd.read_csv('data/customers.eCommerce.csv')\n",
    "\n",
    "# geolocation\n",
    "geolocation = pd.read_csv('data/geolocation.eCommerce.csv')\n",
    "\n",
    "# leads_closed\n",
    "leads = pd.read_csv('data/leads_closed.eCommerce.csv')\n",
    "\n",
    "# lead_qualified\n",
    "lead_qualified = pd.read_csv('data/leads_qualified.eCommerce.csv')\n",
    "\n",
    "# order_items\n",
    "order_items = pd.read_csv('data/order_items.eCommerce.csv')\n",
    "\n",
    "# order_payments\n",
    "order_payment = pd.read_csv('data/order_payments.eCommerce.csv')\n",
    "\n",
    "# order_reviews\n",
    "order_reviews = pd.read_csv('data/order_reviews.eCommerce.csv')\n",
    "\n",
    "# orders\n",
    "orders = pd.read_csv('data/orders.eCommerce.csv')\n",
    "\n",
    "# product_category\n",
    "product_category = pd.read_csv('data/product_category_name_translation.eCommerce.csv')\n",
    "\n",
    "# products\n",
    "products = pd.read_csv('data/products.eCommerce.csv')\n",
    "\n",
    "# sellers\n",
    "sellers = pd.read_csv('data/sellers.eCommerce.csv')"
   ],
   "id": "3191a67429b40c6d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Products",
   "id": "d34817c8797075f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:28.542290Z",
     "start_time": "2025-06-18T16:09:28.532323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missing percent\n",
    "print(products.isnull().sum() * 100 / len(products))\n",
    "print('=====================================')\n",
    "print(product_category.isnull().sum() * 100 / len(product_category))"
   ],
   "id": "9c93b0d90ff2294c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id                    0.000000\n",
      "product_category_name         1.851234\n",
      "product_name_lenght           1.851234\n",
      "product_description_lenght    1.851234\n",
      "product_photos_qty            1.851234\n",
      "product_weight_g              0.006070\n",
      "product_length_cm             0.006070\n",
      "product_height_cm             0.006070\n",
      "product_width_cm              0.006070\n",
      "dtype: float64\n",
      "=====================================\n",
      "product_category_name            0.0\n",
      "product_category_name_english    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:28.866583Z",
     "start_time": "2025-06-18T16:09:28.620894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# join products and products category\n",
    "# Left join to get english names\n",
    "products_new = pd.merge(\n",
    "    products,\n",
    "    product_category,\n",
    "    how='left',\n",
    "    on='product_category_name'\n",
    ")\n",
    "# Check missing percent\n",
    "print(products_new.isna().sum() * 100 / len(products_new))\n",
    "\n",
    "# # Drop missing\n",
    "products_new.dropna(inplace=True)\n",
    "\n",
    "# Drop project category name\n",
    "products_new.drop(columns='product_category_name', inplace=True)\n",
    "\n",
    "# Check missing percent\n",
    "print('------------------------------------------------------------------')\n",
    "print(products_new.isna().sum() * 100 / len(products_new))\n",
    "\n",
    "# Check for duplicates\n",
    "print('------------------------------------------------------------------')\n",
    "print('Duplicates in products: {}'.format(products_new.duplicated().sum()))\n",
    "\n",
    "# Save products_new\n",
    "products_new.to_csv('data/products_new.csv', index=False)"
   ],
   "id": "3b24985020395ad9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id                       0.000000\n",
      "product_category_name            1.851234\n",
      "product_name_lenght              1.851234\n",
      "product_description_lenght       1.851234\n",
      "product_photos_qty               1.851234\n",
      "product_weight_g                 0.006070\n",
      "product_length_cm                0.006070\n",
      "product_height_cm                0.006070\n",
      "product_width_cm                 0.006070\n",
      "product_category_name_english    1.890686\n",
      "dtype: float64\n",
      "------------------------------------------------------------------\n",
      "product_id                       0.0\n",
      "product_name_lenght              0.0\n",
      "product_description_lenght       0.0\n",
      "product_photos_qty               0.0\n",
      "product_weight_g                 0.0\n",
      "product_length_cm                0.0\n",
      "product_height_cm                0.0\n",
      "product_width_cm                 0.0\n",
      "product_category_name_english    0.0\n",
      "dtype: float64\n",
      "------------------------------------------------------------------\n",
      "Duplicates in products: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Orders",
   "id": "11d7ad6f2f27b0a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:29.167632Z",
     "start_time": "2025-06-18T16:09:29.057845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing percent\n",
    "print(orders.isna().sum() * 100 / len(orders))\n",
    "\n",
    "print('=====================================')\n",
    "print(order_reviews.isna().sum() * 100 / len(order_reviews))\n",
    "\n",
    "print('=====================================')\n",
    "print(order_payment.isna().sum() * 100 / len(order_payment))\n",
    "\n",
    "print('=====================================')\n",
    "print(order_items.isna().sum() * 100 / len(order_items))"
   ],
   "id": "a07e89a1c52ade37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         0.000000\n",
      "customer_id                      0.000000\n",
      "order_status                     0.000000\n",
      "order_purchase_timestamp         0.000000\n",
      "order_approved_at                0.160899\n",
      "order_delivered_carrier_date     1.793023\n",
      "order_delivered_customer_date    2.981668\n",
      "order_estimated_delivery_date    0.000000\n",
      "dtype: float64\n",
      "=====================================\n",
      "review_id                   0.530945\n",
      "order_id                    2.667138\n",
      "review_score                2.805604\n",
      "review_comment_title       88.535987\n",
      "review_comment_message     60.804630\n",
      "review_creation_date        8.902873\n",
      "review_answer_timestamp     8.920062\n",
      "dtype: float64\n",
      "=====================================\n",
      "order_id                0.0\n",
      "payment_sequential      0.0\n",
      "payment_type            0.0\n",
      "payment_installments    0.0\n",
      "payment_value           0.0\n",
      "dtype: float64\n",
      "=====================================\n",
      "order_id               0.0\n",
      "order_item_id          0.0\n",
      "product_id             0.0\n",
      "seller_id              0.0\n",
      "shipping_limit_date    0.0\n",
      "price                  0.0\n",
      "freight_value          0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:29.362180Z",
     "start_time": "2025-06-18T16:09:29.230301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Customer reviews extract\n",
    "cus_reviews = order_reviews.copy(deep=True)\n",
    "cus_reviews.dropna(inplace=True)\n",
    "cus_reviews.info()\n",
    "# save reviews\n",
    "cus_reviews.to_csv('data/cus_reviews.csv', index=False)"
   ],
   "id": "adec0016a8e4154e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8919 entries, 9 to 104695\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   review_id                8919 non-null   object\n",
      " 1   order_id                 8919 non-null   object\n",
      " 2   review_score             8919 non-null   object\n",
      " 3   review_comment_title     8919 non-null   object\n",
      " 4   review_comment_message   8919 non-null   object\n",
      " 5   review_creation_date     8919 non-null   object\n",
      " 6   review_answer_timestamp  8919 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 557.4+ KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:29.443533Z",
     "start_time": "2025-06-18T16:09:29.423234Z"
    }
   },
   "cell_type": "code",
   "source": "cus_reviews",
   "id": "aff14915fab22b6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               review_id                          order_id  \\\n",
       "9       8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "16      3948b09f7c818e2d86c9a546758b2335  e51478e7e277a83743b6f9991dbfa3fb   \n",
       "20      373cbeecea8286a2b66c97b1b157ec46  583174fbe37d3d5f0d6661be3aad1786   \n",
       "23      d21bbc789670eab777d27372ab9094cc  4fc44d78867142c627497b60a7e0228a   \n",
       "38      c92cdd7dd544a01aa35137f901669cdf  37e7875cdce5a9e5b3a692971f370151   \n",
       "...                                  ...                               ...   \n",
       "104645  4e1fad431debcccf54b569356ab41b50  f419e615bbdeb34741d4bdd661ff8599   \n",
       "104665  6740912e6b4bb99b3fad98dbc0f18afe  a40874087359fab9b2c8a3aef56a97ad   \n",
       "104686  0e7bc73fde6782891898ea71443f9904  bd78f91afbb1ecbc6124974c5e813043   \n",
       "104690  58be140ccdc12e8908ff7fd2ba5c7cb0  0ebf8e35b9807ee2d717922d5663ccdb   \n",
       "104695  2ee221b28e5b6fceffac59487ed39348  f2d12dd37eaef72ed7b1186b2edefbcd   \n",
       "\n",
       "       review_score      review_comment_title  \\\n",
       "9                 4                 recomendo   \n",
       "16                5           Super recomendo   \n",
       "20                1  NÃ£o chegou meu produto    \n",
       "23                5                    Ã“timo   \n",
       "38                4                Muito bom.   \n",
       "...             ...                       ...   \n",
       "104645            5                 Recomendo   \n",
       "104665            5                ConfiÃ¡vel   \n",
       "104686            4                      ðŸ‘   \n",
       "104690            5        muito bom produto    \n",
       "104695            2            Foto enganosa    \n",
       "\n",
       "                                   review_comment_message  \\\n",
       "9       aparelho eficiente. no site a marca do aparelh...   \n",
       "16      Vendedor confiÃ¡vel, produto ok e entrega ante...   \n",
       "20                                               PÃ©ssimo   \n",
       "23                                           Loja nota 10   \n",
       "38      Recebi exatamente o que esperava. As demais en...   \n",
       "...                                                   ...   \n",
       "104645          Recomendo, compra segura entrega correta.   \n",
       "104665  Veio tudo certinho, lacradinho, dentro do praz...   \n",
       "104686                                          Aprovado!   \n",
       "104690  Ficamos muito satisfeitos com o produto, atend...   \n",
       "104695  Foto muito diferente principalmente a graninha...   \n",
       "\n",
       "       review_creation_date review_answer_timestamp  \n",
       "9            5/22/2018 0:00         5/23/2018 16:45  \n",
       "16           5/23/2018 0:00          5/24/2018 3:00  \n",
       "20           8/15/2018 0:00          8/15/2018 4:10  \n",
       "23           7/10/2018 0:00         7/11/2018 14:10  \n",
       "38            6/7/2018 0:00          6/9/2018 18:44  \n",
       "...                     ...                     ...  \n",
       "104645       8/17/2018 0:00         8/18/2018 12:07  \n",
       "104665       6/22/2018 0:00         6/23/2018 17:28  \n",
       "104686        7/4/2018 0:00           7/5/2018 0:25  \n",
       "104690       6/30/2018 0:00          7/2/2018 23:09  \n",
       "104695       3/28/2018 0:00          5/25/2018 1:23  \n",
       "\n",
       "[8919 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>5/22/2018 0:00</td>\n",
       "      <td>5/23/2018 16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>5</td>\n",
       "      <td>Super recomendo</td>\n",
       "      <td>Vendedor confiÃ¡vel, produto ok e entrega ante...</td>\n",
       "      <td>5/23/2018 0:00</td>\n",
       "      <td>5/24/2018 3:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>373cbeecea8286a2b66c97b1b157ec46</td>\n",
       "      <td>583174fbe37d3d5f0d6661be3aad1786</td>\n",
       "      <td>1</td>\n",
       "      <td>NÃ£o chegou meu produto</td>\n",
       "      <td>PÃ©ssimo</td>\n",
       "      <td>8/15/2018 0:00</td>\n",
       "      <td>8/15/2018 4:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>d21bbc789670eab777d27372ab9094cc</td>\n",
       "      <td>4fc44d78867142c627497b60a7e0228a</td>\n",
       "      <td>5</td>\n",
       "      <td>Ã“timo</td>\n",
       "      <td>Loja nota 10</td>\n",
       "      <td>7/10/2018 0:00</td>\n",
       "      <td>7/11/2018 14:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>c92cdd7dd544a01aa35137f901669cdf</td>\n",
       "      <td>37e7875cdce5a9e5b3a692971f370151</td>\n",
       "      <td>4</td>\n",
       "      <td>Muito bom.</td>\n",
       "      <td>Recebi exatamente o que esperava. As demais en...</td>\n",
       "      <td>6/7/2018 0:00</td>\n",
       "      <td>6/9/2018 18:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104645</th>\n",
       "      <td>4e1fad431debcccf54b569356ab41b50</td>\n",
       "      <td>f419e615bbdeb34741d4bdd661ff8599</td>\n",
       "      <td>5</td>\n",
       "      <td>Recomendo</td>\n",
       "      <td>Recomendo, compra segura entrega correta.</td>\n",
       "      <td>8/17/2018 0:00</td>\n",
       "      <td>8/18/2018 12:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104665</th>\n",
       "      <td>6740912e6b4bb99b3fad98dbc0f18afe</td>\n",
       "      <td>a40874087359fab9b2c8a3aef56a97ad</td>\n",
       "      <td>5</td>\n",
       "      <td>ConfiÃ¡vel</td>\n",
       "      <td>Veio tudo certinho, lacradinho, dentro do praz...</td>\n",
       "      <td>6/22/2018 0:00</td>\n",
       "      <td>6/23/2018 17:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104686</th>\n",
       "      <td>0e7bc73fde6782891898ea71443f9904</td>\n",
       "      <td>bd78f91afbb1ecbc6124974c5e813043</td>\n",
       "      <td>4</td>\n",
       "      <td>ðŸ‘</td>\n",
       "      <td>Aprovado!</td>\n",
       "      <td>7/4/2018 0:00</td>\n",
       "      <td>7/5/2018 0:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104690</th>\n",
       "      <td>58be140ccdc12e8908ff7fd2ba5c7cb0</td>\n",
       "      <td>0ebf8e35b9807ee2d717922d5663ccdb</td>\n",
       "      <td>5</td>\n",
       "      <td>muito bom produto</td>\n",
       "      <td>Ficamos muito satisfeitos com o produto, atend...</td>\n",
       "      <td>6/30/2018 0:00</td>\n",
       "      <td>7/2/2018 23:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104695</th>\n",
       "      <td>2ee221b28e5b6fceffac59487ed39348</td>\n",
       "      <td>f2d12dd37eaef72ed7b1186b2edefbcd</td>\n",
       "      <td>2</td>\n",
       "      <td>Foto enganosa</td>\n",
       "      <td>Foto muito diferente principalmente a graninha...</td>\n",
       "      <td>3/28/2018 0:00</td>\n",
       "      <td>5/25/2018 1:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8919 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:30.103663Z",
     "start_time": "2025-06-18T16:09:29.598481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join orders and related datasets | method chaining\n",
    "orders_new = pd.merge(\n",
    "    order_reviews,\n",
    "    order_payment,\n",
    "    how='left',\n",
    "    on='order_id'\n",
    ").merge(\n",
    "    orders,\n",
    "    how='left',\n",
    "    on='order_id'\n",
    ").merge(\n",
    "    order_items,\n",
    "    how='left',\n",
    "    on='order_id'\n",
    ")"
   ],
   "id": "ef084aa0348ac26b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:31.938674Z",
     "start_time": "2025-06-18T16:09:30.188985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check missing percent\n",
    "print(orders_new.isna().sum() * 100 / len(orders_new))\n",
    "\n",
    "# Drop reviews and title\n",
    "orders_new.drop(\n",
    "    columns=[\n",
    "        'review_comment_title',\n",
    "        'review_comment_message'\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Drop missing\n",
    "orders_new.dropna(inplace=True)\n",
    "\n",
    "# Check duplicates\n",
    "print('---------------------------------')\n",
    "print('Duplicates in orders: {}'.format(orders_new.duplicated().sum()))\n",
    "\n",
    "# Save orders_new\n",
    "orders_new.to_csv('data/orders_new.csv', index=False)"
   ],
   "id": "a60bd305ad49fc1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id                         0.449689\n",
      "order_id                          2.258959\n",
      "review_score                      2.376234\n",
      "review_comment_title             88.332349\n",
      "review_comment_message           59.312041\n",
      "review_creation_date              8.362922\n",
      "review_answer_timestamp           8.377480\n",
      "payment_sequential                4.446745\n",
      "payment_type                      4.446745\n",
      "payment_installments              4.446745\n",
      "payment_value                     4.446745\n",
      "customer_id                       4.444319\n",
      "order_status                      4.444319\n",
      "order_purchase_timestamp          4.444319\n",
      "order_approved_at                 4.583431\n",
      "order_delivered_carrier_date      6.100727\n",
      "order_delivered_customer_date     7.101204\n",
      "order_estimated_delivery_date     4.444319\n",
      "order_item_id                     5.102676\n",
      "product_id                        5.102676\n",
      "seller_id                         5.102676\n",
      "shipping_limit_date               5.102676\n",
      "price                             5.102676\n",
      "freight_value                     5.102676\n",
      "dtype: float64\n",
      "---------------------------------\n",
      "Duplicates in orders: 0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Leads",
   "id": "2c64d0b9ddfe42fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:32.162825Z",
     "start_time": "2025-06-18T16:09:32.151493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missing percent\n",
    "print(lead_qualified.isna().sum() * 100 / len(lead_qualified))\n",
    "print('---------------------------------------------------')\n",
    "print(leads.isna().sum() / len(leads))\n"
   ],
   "id": "d7f9fde578d18766",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mql_id                0.00\n",
      "first_contact_date    0.00\n",
      "landing_page_id       0.00\n",
      "origin                0.75\n",
      "dtype: float64\n",
      "---------------------------------------------------\n",
      "mql_id                           0.000000\n",
      "seller_id                        0.000000\n",
      "sdr_id                           0.000000\n",
      "sr_id                            0.000000\n",
      "won_date                         0.000000\n",
      "business_segment                 0.001188\n",
      "lead_type                        0.007126\n",
      "lead_behaviour_profile           0.210214\n",
      "has_company                      0.925178\n",
      "has_gtin                         0.923990\n",
      "average_stock                    0.921615\n",
      "business_type                    0.011876\n",
      "declared_product_catalog_size    0.918052\n",
      "declared_monthly_revenue         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:32.307046Z",
     "start_time": "2025-06-18T16:09:32.295478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join leads\n",
    "lead_new = pd.merge(\n",
    "    lead_qualified,\n",
    "    leads,\n",
    "    how='left',\n",
    "    on='mql_id'\n",
    ")"
   ],
   "id": "3c25eba25a48a071",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:32.540938Z",
     "start_time": "2025-06-18T16:09:32.461921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check missing values\n",
    "print(lead_new.isna().sum() * 100 / len(lead_new))\n",
    "\n",
    "\n",
    "# Drop missing values\n",
    "# lead_new.dropna(inplace=True)\n",
    "\n",
    "# Check duplicates\n",
    "print('---------------------------------------')\n",
    "print('Duplicates in leads: ', lead_new.duplicated().sum())\n",
    "\n",
    "# Save leads dataset\n",
    "lead_new.to_csv('data/lead_new.csv', index=False)"
   ],
   "id": "6aa1bd6d39f8b91a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mql_id                            0.0000\n",
      "first_contact_date                0.0000\n",
      "landing_page_id                   0.0000\n",
      "origin                            0.7500\n",
      "seller_id                        89.4750\n",
      "sdr_id                           89.4750\n",
      "sr_id                            89.4750\n",
      "won_date                         89.4750\n",
      "business_segment                 89.4875\n",
      "lead_type                        89.5500\n",
      "lead_behaviour_profile           91.6875\n",
      "has_company                      99.2125\n",
      "has_gtin                         99.2000\n",
      "average_stock                    99.1750\n",
      "business_type                    89.6000\n",
      "declared_product_catalog_size    99.1375\n",
      "declared_monthly_revenue         89.4750\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Duplicates in leads:  0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Customers, Sellers and Geolocation",
   "id": "eb5b0ee17a2efb83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:32.760239Z",
     "start_time": "2025-06-18T16:09:32.649228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missing percent in customers\n",
    "print(customers.isna().sum() * 100 / len(customers))\n",
    "\n",
    "# Duplicates customers\n",
    "print('------------------------------------')\n",
    "print('Duplicates in customers: ', customers.duplicated().sum())"
   ],
   "id": "3e2c345544508f32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id                 0.0\n",
      "customer_unique_id          0.0\n",
      "customer_zip_code_prefix    0.0\n",
      "customer_city               0.0\n",
      "customer_state              0.0\n",
      "dtype: float64\n",
      "------------------------------------\n",
      "Duplicates in customers:  0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:33.494784Z",
     "start_time": "2025-06-18T16:09:32.835274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for duplicates in geolocation\n",
    "print('Duplicates in geolocation: ', geolocation.duplicated().sum())\n",
    "\n",
    "# Drop duplicates\n",
    "geolocation.drop_duplicates(inplace=True)"
   ],
   "id": "be8f59a16246ca81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in geolocation:  261836\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:33.762890Z",
     "start_time": "2025-06-18T16:09:33.554702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reduce geolocations using mean for unique zip/city/state --alternative is median`\n",
    "geolocation_reduced = geolocation.groupby(\n",
    "    ['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state']\n",
    ").agg(\n",
    "    geolocation_lat=('geolocation_lat', 'mean'),\n",
    "    geolocation_lng=('geolocation_lng', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Join both geolocation and customers\n",
    "customers_geo = pd.merge(\n",
    "    customers,\n",
    "    geolocation_reduced,\n",
    "    how='left',\n",
    "    left_on=['customer_zip_code_prefix', 'customer_city', 'customer_state'],\n",
    "    right_on=['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state']\n",
    ")\n",
    "\n",
    "# Drop the redundant geolocation columns if they're identical to customer ones after merge\n",
    "customers_geo.drop(columns=[\n",
    "    'geolocation_zip_code_prefix',\n",
    "    'geolocation_city',\n",
    "    'geolocation_state'\n",
    "], inplace=True)\n",
    "\n",
    "# Drop missing values\n",
    "customers_geo.dropna(inplace=True)\n",
    "\n",
    "# rename geolocation\n",
    "customers_geo.rename(\n",
    "    columns={\n",
    "        'geolocation_lat': 'customer_latitude',\n",
    "        'geolocation_lng': 'customer_longitude'\n",
    "    }\n",
    ", inplace=True)\n",
    "\n",
    "# Info\n",
    "customers_geo.info()"
   ],
   "id": "6ea510de20300d8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99123 entries, 0 to 99440\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   customer_id               99123 non-null  object \n",
      " 1   customer_unique_id        99123 non-null  object \n",
      " 2   customer_zip_code_prefix  99123 non-null  int64  \n",
      " 3   customer_city             99123 non-null  object \n",
      " 4   customer_state            99123 non-null  object \n",
      " 5   customer_latitude         99123 non-null  float64\n",
      " 6   customer_longitude        99123 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.269246Z",
     "start_time": "2025-06-18T16:09:33.826157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save customers_geo\n",
    "customers_geo.to_csv('data/customers_geo.csv', index=False)"
   ],
   "id": "4eb14e98fb1bed20",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.338091Z",
     "start_time": "2025-06-18T16:09:34.330581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missing percent in sellers\n",
    "print(sellers.isna().sum() *100/ len(sellers))\n",
    "# Duplicates sellers\n",
    "print('------------------------------------')\n",
    "print('Duplicates in customers: ', sellers.duplicated().sum())"
   ],
   "id": "bddc50ab3053212e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seller_id                 0.0\n",
      "seller_zip_code_prefix    0.0\n",
      "seller_city               0.0\n",
      "seller_state              0.0\n",
      "dtype: float64\n",
      "------------------------------------\n",
      "Duplicates in customers:  0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.484777Z",
     "start_time": "2025-06-18T16:09:34.456373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join both geolocation and customers\n",
    "sellers_geo = pd.merge(\n",
    "    sellers,\n",
    "    geolocation_reduced,\n",
    "    how='left',\n",
    "    left_on=['seller_zip_code_prefix', 'seller_city', 'seller_state'],\n",
    "    right_on=['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state']\n",
    ")\n",
    "\n",
    "# Drop the redundant geolocation columns if they're identical to customer ones after merge\n",
    "sellers_geo.drop(columns=[\n",
    "    'geolocation_zip_code_prefix',\n",
    "    'geolocation_city',\n",
    "    'geolocation_state'\n",
    "], inplace=True)\n",
    "\n",
    "# Drop missing\n",
    "sellers_geo.dropna(inplace=True)\n",
    "\n",
    "# rename geolocation\n",
    "sellers_geo.rename(\n",
    "    columns={\n",
    "        'geolocation_lat': 'seller_latitude',\n",
    "        'geolocation_lng': 'seller_longitude'\n",
    "    }\n",
    ", inplace=True)\n",
    "\n",
    "\n",
    "# Info\n",
    "sellers_geo.info()"
   ],
   "id": "197ceb151c4d4845",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2958 entries, 0 to 3094\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   seller_id               2958 non-null   object \n",
      " 1   seller_zip_code_prefix  2958 non-null   int64  \n",
      " 2   seller_city             2958 non-null   object \n",
      " 3   seller_state            2958 non-null   object \n",
      " 4   seller_latitude         2958 non-null   float64\n",
      " 5   seller_longitude        2958 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 161.8+ KB\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.594226Z",
     "start_time": "2025-06-18T16:09:34.571277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save sellers geo\n",
    "sellers_geo.to_csv('data/sellers_geo.csv', index=False)"
   ],
   "id": "a1009b915898763e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.731651Z",
     "start_time": "2025-06-18T16:09:34.682134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join sellers and customers\n",
    "customers_sellers_geo = pd.merge(\n",
    "    customers_geo,\n",
    "    sellers_geo,\n",
    "    how='left',\n",
    "    left_on=['customer_zip_code_prefix', 'customer_city', 'customer_state'],\n",
    "    right_on=['seller_zip_code_prefix', 'seller_city', 'seller_state']\n",
    ")\n",
    "\n",
    "\n",
    "customers_sellers_geo.rename(\n",
    "    columns={\n",
    "        'customer_zip_code_prefix': 'customer_zip_code',\n",
    "        'seller_zip_code_prefix': 'seller_zip_code'\n",
    "    }\n",
    ", inplace=True)"
   ],
   "id": "c9b4339ed3ad3d73",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:34.871295Z",
     "start_time": "2025-06-18T16:09:34.839739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Missing percent\n",
    "customers_sellers_geo.isna().sum() * 100 / len(customers_sellers_geo)"
   ],
   "id": "cbc41653d3518596",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id            0.000000\n",
       "customer_unique_id     0.000000\n",
       "customer_zip_code      0.000000\n",
       "customer_city          0.000000\n",
       "customer_state         0.000000\n",
       "customer_latitude      0.000000\n",
       "customer_longitude     0.000000\n",
       "seller_id             62.948478\n",
       "seller_zip_code       62.948478\n",
       "seller_city           62.948478\n",
       "seller_state          62.948478\n",
       "seller_latitude       62.948478\n",
       "seller_longitude      62.948478\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:35.870963Z",
     "start_time": "2025-06-18T16:09:35.003291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save customer_sellers_geo\n",
    "customers_sellers_geo.to_csv('data/customers_sellers_geo.csv', index=False)"
   ],
   "id": "d014b7c570a6f9b0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:37.540639Z",
     "start_time": "2025-06-18T16:09:36.009317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join orders and customer_sellers_geo\n",
    "new_orders = pd.merge(\n",
    "    orders_new,\n",
    "    customers_sellers_geo,\n",
    "    how='left',\n",
    "    left_on=['customer_id'],\n",
    "    right_on=['customer_id'],\n",
    ")\n",
    "\n",
    "# Join products\n",
    "new_orders = new_orders.merge(\n",
    "    products_new,\n",
    "    how='left',\n",
    "    on=['product_id'],)\n",
    "\n",
    "# Drop missing sellers id columns\n",
    "new_orders.drop(columns=[\n",
    "    'seller_id_y'\n",
    "], inplace=True)\n",
    "\n",
    "\n",
    "# rename to sellers_id\n",
    "new_orders.rename(\n",
    "    columns={\n",
    "        'seller_id_x': 'seller_id',\n",
    "    }\n",
    ", inplace=True)\n",
    "\n",
    "# Drop missing\n",
    "new_orders.dropna(inplace=True)\n",
    "\n",
    "# save new orders_dataset\n",
    "new_orders.to_csv('data/new_orders.csv', index=False)"
   ],
   "id": "604d23605d67069a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:37.848360Z",
     "start_time": "2025-06-18T16:09:37.784275Z"
    }
   },
   "cell_type": "code",
   "source": "new_orders.info()",
   "id": "2e5742df2e507b47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 47545 entries, 2 to 128188\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   review_id                      47545 non-null  object \n",
      " 1   order_id                       47545 non-null  object \n",
      " 2   review_score                   47545 non-null  object \n",
      " 3   review_creation_date           47545 non-null  object \n",
      " 4   review_answer_timestamp        47545 non-null  object \n",
      " 5   payment_sequential             47545 non-null  float64\n",
      " 6   payment_type                   47545 non-null  object \n",
      " 7   payment_installments           47545 non-null  float64\n",
      " 8   payment_value                  47545 non-null  float64\n",
      " 9   customer_id                    47545 non-null  object \n",
      " 10  order_status                   47545 non-null  object \n",
      " 11  order_purchase_timestamp       47545 non-null  object \n",
      " 12  order_approved_at              47545 non-null  object \n",
      " 13  order_delivered_carrier_date   47545 non-null  object \n",
      " 14  order_delivered_customer_date  47545 non-null  object \n",
      " 15  order_estimated_delivery_date  47545 non-null  object \n",
      " 16  order_item_id                  47545 non-null  float64\n",
      " 17  product_id                     47545 non-null  object \n",
      " 18  seller_id                      47545 non-null  object \n",
      " 19  shipping_limit_date            47545 non-null  object \n",
      " 20  price                          47545 non-null  float64\n",
      " 21  freight_value                  47545 non-null  float64\n",
      " 22  customer_unique_id             47545 non-null  object \n",
      " 23  customer_zip_code              47545 non-null  float64\n",
      " 24  customer_city                  47545 non-null  object \n",
      " 25  customer_state                 47545 non-null  object \n",
      " 26  customer_latitude              47545 non-null  float64\n",
      " 27  customer_longitude             47545 non-null  float64\n",
      " 28  seller_zip_code                47545 non-null  float64\n",
      " 29  seller_city                    47545 non-null  object \n",
      " 30  seller_state                   47545 non-null  object \n",
      " 31  seller_latitude                47545 non-null  float64\n",
      " 32  seller_longitude               47545 non-null  float64\n",
      " 33  product_name_lenght            47545 non-null  float64\n",
      " 34  product_description_lenght     47545 non-null  float64\n",
      " 35  product_photos_qty             47545 non-null  float64\n",
      " 36  product_weight_g               47545 non-null  float64\n",
      " 37  product_length_cm              47545 non-null  float64\n",
      " 38  product_height_cm              47545 non-null  float64\n",
      " 39  product_width_cm               47545 non-null  float64\n",
      " 40  product_category_name_english  47545 non-null  object \n",
      "dtypes: float64(19), object(22)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:38.063324Z",
     "start_time": "2025-06-18T16:09:38.001799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_df = pd.merge(\n",
    "    new_orders,\n",
    "    lead_new,\n",
    "    how='left',\n",
    "    on='seller_id'\n",
    ")"
   ],
   "id": "37d91b6fa610d663",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:09:39.371955Z",
     "start_time": "2025-06-18T16:09:38.165721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save df\n",
    "final_df.to_csv('data/final_df.csv', index=False)"
   ],
   "id": "c42060ae36c5b008",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T16:10:08.424405Z",
     "start_time": "2025-06-18T16:10:08.417802Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.columns",
   "id": "f15acb8c9ce6868f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'order_id', 'review_score', 'review_creation_date',\n",
       "       'review_answer_timestamp', 'payment_sequential', 'payment_type',\n",
       "       'payment_installments', 'payment_value', 'customer_id', 'order_status',\n",
       "       'order_purchase_timestamp', 'order_approved_at',\n",
       "       'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
       "       'order_estimated_delivery_date', 'order_item_id', 'product_id',\n",
       "       'seller_id', 'shipping_limit_date', 'price', 'freight_value',\n",
       "       'customer_unique_id', 'customer_zip_code', 'customer_city',\n",
       "       'customer_state', 'customer_latitude', 'customer_longitude',\n",
       "       'seller_zip_code', 'seller_city', 'seller_state', 'seller_latitude',\n",
       "       'seller_longitude', 'product_name_lenght', 'product_description_lenght',\n",
       "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
       "       'product_height_cm', 'product_width_cm',\n",
       "       'product_category_name_english', 'mql_id', 'first_contact_date',\n",
       "       'landing_page_id', 'origin', 'sdr_id', 'sr_id', 'won_date',\n",
       "       'business_segment', 'lead_type', 'lead_behaviour_profile',\n",
       "       'has_company', 'has_gtin', 'average_stock', 'business_type',\n",
       "       'declared_product_catalog_size', 'declared_monthly_revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T18:36:05.333200Z",
     "start_time": "2025-06-20T18:36:04.301634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df =  pd.read_csv('data/final_df.csv')"
   ],
   "id": "96c453133c0dbc4c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T18:36:05.419942Z",
     "start_time": "2025-06-20T18:36:05.355309Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "a1fdf23a5d412b1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47545 entries, 0 to 47544\n",
      "Data columns (total 57 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   review_id                      47545 non-null  object \n",
      " 1   order_id                       47545 non-null  object \n",
      " 2   review_score                   47545 non-null  int64  \n",
      " 3   review_creation_date           47545 non-null  object \n",
      " 4   review_answer_timestamp        47545 non-null  object \n",
      " 5   payment_sequential             47545 non-null  float64\n",
      " 6   payment_type                   47545 non-null  object \n",
      " 7   payment_installments           47545 non-null  float64\n",
      " 8   payment_value                  47545 non-null  float64\n",
      " 9   customer_id                    47545 non-null  object \n",
      " 10  order_status                   47545 non-null  object \n",
      " 11  order_purchase_timestamp       47545 non-null  object \n",
      " 12  order_approved_at              47545 non-null  object \n",
      " 13  order_delivered_carrier_date   47545 non-null  object \n",
      " 14  order_delivered_customer_date  47545 non-null  object \n",
      " 15  order_estimated_delivery_date  47545 non-null  object \n",
      " 16  order_item_id                  47545 non-null  float64\n",
      " 17  product_id                     47545 non-null  object \n",
      " 18  seller_id                      47545 non-null  object \n",
      " 19  shipping_limit_date            47545 non-null  object \n",
      " 20  price                          47545 non-null  float64\n",
      " 21  freight_value                  47545 non-null  float64\n",
      " 22  customer_unique_id             47545 non-null  object \n",
      " 23  customer_zip_code              47545 non-null  float64\n",
      " 24  customer_city                  47545 non-null  object \n",
      " 25  customer_state                 47545 non-null  object \n",
      " 26  customer_latitude              47545 non-null  float64\n",
      " 27  customer_longitude             47545 non-null  float64\n",
      " 28  seller_zip_code                47545 non-null  float64\n",
      " 29  seller_city                    47545 non-null  object \n",
      " 30  seller_state                   47545 non-null  object \n",
      " 31  seller_latitude                47545 non-null  float64\n",
      " 32  seller_longitude               47545 non-null  float64\n",
      " 33  product_name_lenght            47545 non-null  float64\n",
      " 34  product_description_lenght     47545 non-null  float64\n",
      " 35  product_photos_qty             47545 non-null  float64\n",
      " 36  product_weight_g               47545 non-null  float64\n",
      " 37  product_length_cm              47545 non-null  float64\n",
      " 38  product_height_cm              47545 non-null  float64\n",
      " 39  product_width_cm               47545 non-null  float64\n",
      " 40  product_category_name_english  47545 non-null  object \n",
      " 41  mql_id                         2234 non-null   object \n",
      " 42  first_contact_date             2234 non-null   object \n",
      " 43  landing_page_id                2234 non-null   object \n",
      " 44  origin                         2230 non-null   object \n",
      " 45  sdr_id                         2234 non-null   object \n",
      " 46  sr_id                          2234 non-null   object \n",
      " 47  won_date                       2234 non-null   object \n",
      " 48  business_segment               2234 non-null   object \n",
      " 49  lead_type                      2210 non-null   object \n",
      " 50  lead_behaviour_profile         1498 non-null   object \n",
      " 51  has_company                    12 non-null     float64\n",
      " 52  has_gtin                       12 non-null     float64\n",
      " 53  average_stock                  12 non-null     object \n",
      " 54  business_type                  2233 non-null   object \n",
      " 55  declared_product_catalog_size  0 non-null      float64\n",
      " 56  declared_monthly_revenue       2234 non-null   float64\n",
      "dtypes: float64(23), int64(1), object(33)\n",
      "memory usage: 20.7+ MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Customer Churn Prediction",
   "id": "a966545d790580a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "#\n",
    "# # --- Sample Data ---\n",
    "# # In your environment, you would use your full DataFrame 'df'\n",
    "# data = {\n",
    "#     'customer_unique_id': ['a', 'b', 'a', 'c', 'b', 'd'],\n",
    "#     'order_purchase_timestamp': ['2018-01-01', '2017-05-01', '2018-09-01', '2018-08-01', '2018-09-05', '2017-01-01'],\n",
    "#     'payment_value': [100, 200, 50, 300, 150, 80]\n",
    "# }\n",
    "# df_churn = pd.DataFrame(data)\n",
    "# df_churn['order_purchase_timestamp'] = pd.to_datetime(df_churn['order_purchase_timestamp'])\n",
    "#\n",
    "#\n",
    "# # 1. Feature Engineering (RFM - Recency, Frequency, Monetary)\n",
    "# # Assume today is '2018-10-01' for this calculation\n",
    "# snapshot_date = pd.to_datetime('2018-10-01')\n",
    "#\n",
    "# # Calculate Recency, Frequency, and Monetary value for each customer\n",
    "# rfm = df_churn.groupby('customer_unique_id').agg({\n",
    "#     'order_purchase_timestamp': lambda date: (snapshot_date - date.max()).days,\n",
    "#     'order_purchase_timestamp': 'count',\n",
    "#     'payment_value': 'sum'\n",
    "# })\n",
    "# rfm.rename(columns={'order_purchase_timestamp': 'recency_and_frequency'}, inplace=True)\n",
    "#\n",
    "# # The aggregation for 'order_purchase_timestamp' results in a tuple when multiple aggregations are used.\n",
    "# # Let's separate them properly.\n",
    "# rfm_calc = df_churn.groupby('customer_unique_id').agg(\n",
    "#     recency=('order_purchase_timestamp', lambda date: (snapshot_date - date.max()).days),\n",
    "#     frequency=('order_purchase_timestamp', 'count'),\n",
    "#     monetary=('payment_value', 'sum')\n",
    "# )\n",
    "#\n",
    "#\n",
    "# # Define Churn: If a customer's last purchase was more than 180 days ago\n",
    "# rfm_calc['churn'] = (rfm_calc['recency'] > 180).astype(int)\n",
    "#\n",
    "# # 2. Data Preprocessing is complete through RFM feature creation\n",
    "#\n",
    "# # 3. Model Training\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "#\n",
    "# # Define features and target\n",
    "# features = ['recency', 'frequency', 'monetary']\n",
    "# target = 'churn'\n",
    "#\n",
    "# X = rfm_calc[features]\n",
    "# y = rfm_calc[target]\n",
    "#\n",
    "# # Split and train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "# model.fit(X_train, y_train)\n",
    "#\n",
    "# # 4. Model Evaluation\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(\"\\nCustomer Churn Prediction Results:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "54e2c1c1ec7d270e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Python Code for Predicting Delivery Delays",
   "id": "18e7d483290ec6c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "#\n",
    "# # This is a sample of your data.\n",
    "# # In your environment, you would load your full dataset like this:\n",
    "# # df = pd.read_csv('your_file_path.csv')\n",
    "#\n",
    "# data = {\n",
    "#     'order_purchase_timestamp': ['2017-10-02 10:56:33', '2018-07-24 20:41:37', '2018-08-08 08:38:49', '2017-11-18 19:28:06', '2018-02-13 21:18:39'],\n",
    "#     'order_delivered_customer_date': ['2017-10-10 21:25:13', '2018-08-07 15:27:45', '2018-08-17 18:06:29', '2017-12-02 00:28:42', '2018-02-16 12:15:33'],\n",
    "#     'order_estimated_delivery_date': ['2017-10-18 00:00:00', '2018-08-13 00:00:00', '2018-09-04 00:00:00', '2017-12-15 00:00:00', '2018-03-09 00:00:00'],\n",
    "#     'customer_state': ['SP', 'SP', 'GO', 'SC', 'SP'],\n",
    "#     'seller_state': ['SP', 'SP', 'SP', 'PR', 'MG'],\n",
    "#     'price': [29.99, 118.70, 159.90, 45.00, 19.90],\n",
    "#     'freight_value': [8.72, 22.76, 19.22, 27.20, 12.79],\n",
    "#     'product_weight_g': [500, 400, 420, 450, 250]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "#\n",
    "#\n",
    "# # 1. Feature Engineering\n",
    "# # Convert date columns to datetime objects\n",
    "# for col in ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']:\n",
    "#     df[col] = pd.to_datetime(df[col])\n",
    "#\n",
    "# # Calculate delivery delay in days\n",
    "# df['delivery_delay'] = (df['order_delivered_customer_date'] - df['order_estimated_delivery_date']).dt.days\n",
    "#\n",
    "# # For simplicity, we'll focus on predicting delays for already delivered orders.\n",
    "# # We will remove orders that were not delivered or have missing delivery dates.\n",
    "# df.dropna(subset=['delivery_delay'], inplace=True)\n",
    "#\n",
    "# # Define features (X) and target (y)\n",
    "# features = ['customer_state', 'seller_state', 'price', 'freight_value', 'product_weight_g']\n",
    "# target = 'delivery_delay'\n",
    "#\n",
    "# X = df[features]\n",
    "# y = df[target]\n",
    "#\n",
    "# # 2. Data Preprocessing\n",
    "# # Identify categorical and numerical features\n",
    "# categorical_features = ['customer_state', 'seller_state']\n",
    "# numerical_features = ['price', 'freight_value', 'product_weight_g']\n",
    "#\n",
    "# # Create preprocessing pipelines for both numerical and categorical data\n",
    "# numerical_transformer = SimpleImputer(strategy='mean')\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "#\n",
    "# # Create a preprocessor object using ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ])\n",
    "#\n",
    "# # 3. Model Training\n",
    "# # Define the model\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "#\n",
    "# # Create the full pipeline\n",
    "# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                            ('regressor', model)])\n",
    "#\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # Train the model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "#\n",
    "# # 4. Model Evaluation\n",
    "# # Make predictions\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "#\n",
    "# # Evaluate the model\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# print(f\"Mean Absolute Error: {mae:.2f} days\")\n",
    "#\n",
    "# # You can now use this trained 'pipeline' to make predictions on new data.\n",
    "# # For example:\n",
    "# # new_data = pd.DataFrame(...)\n",
    "# # predicted_delay = pipeline.predict(new_data)"
   ],
   "id": "b6ac3b0769efa71d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Review Score Prediction",
   "id": "f77b27cb96f65c49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "#\n",
    "# # --- Sample Data ---\n",
    "# # In your environment, you would use your full DataFrame 'df'\n",
    "# data = {\n",
    "#     'review_score': [5, 1, 4, 5, 2],\n",
    "#     'order_delivered_customer_date': ['2017-10-10 21:25:13', '2018-08-07 15:27:45', '2018-08-17 18:06:29', '2017-12-02 00:28:42', None],\n",
    "#     'order_estimated_delivery_date': ['2017-10-18 00:00:00', '2018-08-13 00:00:00', '2018-09-04 00:00:00', '2017-12-15 00:00:00', '2018-03-09 00:00:00'],\n",
    "#     'price': [29.99, 118.70, 159.90, 45.00, 19.90],\n",
    "#     'freight_value': [8.72, 22.76, 19.22, 27.20, 12.79],\n",
    "#     'product_category_name_english': ['bed_bath_table', 'sports_leisure', 'health_beauty', 'computers_accessories', 'bed_bath_table']\n",
    "# }\n",
    "# df_reviews = pd.DataFrame(data)\n",
    "#\n",
    "# # 1. Feature Engineering\n",
    "# # Convert date columns to datetime objects\n",
    "# for col in ['order_delivered_customer_date', 'order_estimated_delivery_date']:\n",
    "#     df_reviews[col] = pd.to_datetime(df_reviews[col])\n",
    "#\n",
    "# # Calculate delivery delay\n",
    "# df_reviews['delivery_delay'] = (df_reviews['order_delivered_customer_date'] - df_reviews['order_estimated_delivery_date']).dt.days\n",
    "#\n",
    "# # For this model, we'll drop rows where the score or key features are missing\n",
    "# df_reviews.dropna(subset=['review_score', 'delivery_delay'], inplace=True)\n",
    "#\n",
    "# # Define features and target\n",
    "# features = ['price', 'freight_value', 'delivery_delay', 'product_category_name_english']\n",
    "# target = 'review_score'\n",
    "#\n",
    "# X = df_reviews[features]\n",
    "# y = df_reviews[target]\n",
    "#\n",
    "# # 2. Data Preprocessing\n",
    "# categorical_features = ['product_category_name_english']\n",
    "# numerical_features = ['price', 'freight_value', 'delivery_delay']\n",
    "#\n",
    "# # Create preprocessing pipelines\n",
    "# numerical_transformer = SimpleImputer(strategy='mean')\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "#\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ])\n",
    "#\n",
    "# # 3. Model Training\n",
    "# # Define the model\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "#\n",
    "# # Create the full pipeline\n",
    "# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                            ('classifier', model)])\n",
    "#\n",
    "# # Split and train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# pipeline.fit(X_train, y_train)\n",
    "#\n",
    "# # 4. Model Evaluation\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# print(\"Review Score Prediction Results:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "e807a87faaa62384"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lead Conversion Prediction",
   "id": "b1f3f582a97b6416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# # --- Sample Data ---\n",
    "# # In your environment, you would use your full DataFrame 'df'\n",
    "# # Note: 'won_date' being not null indicates a conversion\n",
    "# data = {\n",
    "#     'mql_id': ['a', 'b', 'c', 'd', 'e'],\n",
    "#     'landing_page_id': ['lp1', 'lp2', 'lp1', 'lp3', 'lp2'],\n",
    "#     'origin': ['social', 'organic', 'paid', 'social', 'organic'],\n",
    "#     'business_segment': ['food', 'pet', 'health', 'food', 'pet'],\n",
    "#     'lead_type': ['online', 'offline', 'online', 'online', 'offline'],\n",
    "#     'won_date': ['2018-01-01', pd.NaT, '2018-03-01', pd.NaT, '2018-05-01']\n",
    "# }\n",
    "# df_leads = pd.DataFrame(data)\n",
    "#\n",
    "# # 1. Feature Engineering\n",
    "# # Create the target variable: 1 if 'won_date' is not null, 0 otherwise\n",
    "# df_leads['converted'] = df_leads['won_date'].notna().astype(int)\n",
    "# df_leads.drop('won_date', axis=1, inplace=True) # Drop the original date\n",
    "#\n",
    "# # 2. Data Preprocessing\n",
    "# # For this example, we will use one-hot encoding for all categorical features\n",
    "# X = df_leads.drop(['mql_id', 'converted'], axis=1)\n",
    "# y = df_leads['converted']\n",
    "#\n",
    "# # Convert categorical variables into dummy/indicator variables\n",
    "# X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "#\n",
    "#\n",
    "# # 3. Model Training\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "#\n",
    "# # Split and train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# # Logistic Regression is a good starting point for conversion models\n",
    "# model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "# model.fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "# # 4. Model Evaluation\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(\"\\nLead Conversion Prediction Results:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred, zero_division=0))\n",
    "#\n",
    "# # To predict the probability of conversion for new leads:\n",
    "# # new_lead_pred_proba = model.predict_proba(new_lead_data_encoded)[:, 1]"
   ],
   "id": "9de46a9b05e8a201"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
